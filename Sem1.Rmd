---
title: "CompStat/R - Paper 1"
author: "Group 2: Carlo Michaelis, Patrick Molligo, Lukas Ruff"
date: "11 May 2016"
fontsize: 11
lof: false
graphics: true
documentclass: article
output: 
  pdf_document:
    latex_engine: pdflatex
    keep_tex: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Part I

### 1. What are the atomic vector types in R? Explain which value they can take and give an example!

There are six *atomic* (or *basic*) vector types in R:

* **character**: Text, i.e. string variables.
* **numeric**: Real numbers, i.e. float variables.
* **integer**: Integers, i.e. values in  $\mathbb{Z}$.
* **complex**: Complex numbers, i.e. a pair of values with a real and imaginary part.
* **logical**: Boolean variables, i.e. either 1 (`TRUE`) or 0 (`FALSE`).
* **raw**: A raw vector contains fixed-length sequences of bytes.

**Examples**
```{r ExAtomicVectorTypes}
a <- c("blue", "red", "yellow")     ## character
b <- c(pi, exp(1), 0, 1)            ## numeric
c <- 1:10                           ## integer
d <- c(0+1i, 1+1i)                  ## complex
e <- c(TRUE, FALSE)                 ## logical
f <- raw(length = 3L)               ## raw
```

It is important to note, that a vector can only contain elements of the same type. We can check the type of an object using the `class`-function.

### 2. What is the difference between generic and atomic vectors?

*Generic vector* is just another name for *list*. The difference between lists and atomic vectors is, that lists can contain objects of different classes, i.e. the elements of a list do not have to be of the same object type.

### 3. Explain the following statement: “A data frame is a list, but not every list is a data frame.”

A data frame is a special type of list where each element has to be of the same length. We can think of a data frame as a table or matrix, where each row is an observation and each column a different variable. The columns of a data frame are the elements of this special type of list. Therefore, every column can store different types of objects. The length of each element or column are the number of rows or observations. 
Hence, data frames are a subset of lists, i.e. every data frame is a list, but not every list is a data frame because generally, the elements of a list can be of different lengths.


## Part II

The following code will perform a simulation of 100'000'000 samples from a $\mathcal{N}(5,10)$ distribution, i.e. a normal distribution with mean $\mu = 5$ and standard deviation $\sigma = 10$. For reproducibility, we set a seed for the random number generator. In a second step, the cumulative sums of the first 100 samples are computed in two different ways, where the function `cumsum` returns a vector where element $i$ is the cumulative sum up to sample $i$. Finally, we check if the two ways of computing the cumulative sums up to sample 100 result in exactly equal vectors.

The code with comments in detail:

```{r NormSim}
# Set the state of the random number generator (RNG) to 1
set.seed(1)

# Perform simulation of 1e8 samples from a normal distribution with mean 5
# and standard deviation 10
largeVector <- rnorm(1e8, mean=5, sd=10)

# Compute the cumulative sums for the whole "largeVector" and subset the
# first 100 elements
a <- cumsum(largeVector)[1:100]

# Compute the cumulative sums only for the first 100 elements of
# "largeVector"
b <- cumsum(largeVector[1:100])

# Check, whether both ways of computation are exactly identical
identical(a, b)
```

Of course, both ways of computing the cumulative sums for the first 100 samples above have the same result and hence `identical(a, b)` returns `TRUE`, but computation `a` is very inefficient compared to computation `b` since we first apply `cumsum` to the whole `largeVector`, i.e. we compute the cumulative sums for 100'000'000 elements and then only look at the first 100 elements. Computation `b` instead only computes the cumulative sums for the subset of the first 100 elements of `largeVector`.
In the following code, we stop the time for each of the two ways of computation:

```{r Comp1}
# Computation method a
system.time(cumsum(largeVector)[1:100])
```

```{r Comp2}
# Computation method b
system.time(cumsum(largeVector[1:100]))
```

The results prove our reasoning above, since the first computation takes much longer than the second.


## Part III

In our regression analysis, we will analyze the rental prices in Munich from 2003 using the dataset “Münchner Mietspiegel 2003”. The dataset contains 13 variables from 2053 apartments in Munich. The variables are the following:

* **nm**: net rent in EUR
* **nmqm**: net rent per $m^2$ in EUR
* **wfl**: living space in $m^2$
* **rooms**: number of rooms
* **bj**: year of construction
* **bez**: district
* **wohngut**: good residential area? (Y=1, N=0)
* **wohnbest**: best residential area? (Y=1, N=0)
* **ww0**: hot water supply? (Y=0, N=1)
* **zh0**: central heating? (Y=0, N=1)
* **badkach0**: tiled bathroom? (Y=0, N=1)
* **badextra**: optional extras in bathroom? (Y=1, N=0)
* **kueche**: luxury kitchen? (Y=1, N=0)

We would like to predict and explain the rental prices, i.e.\ the dependent variable of our regression analysis will be the net rent in EUR `nm`. All other variables are potential explanatory variables for our linear regression model.

### Data Import, Validation and Cleaning

First, we read the data into our global environment using the `load`-function and have a first look at it using `str` and `summary`:

```{r ReadData}
# Load data
load('miete.Rdata')
# Get a first overview
str(miete)
summary(miete)
```

Before we go into the variables of our data in detail, let's do a quick check on missing values:

```{r MissingVal}
# Check for NA's
sum(is.na(miete))
```

There seem to be no missing values in our dataset. 
Now, let's think about plausibility and the data types of our variables. From the five-number summary (`Min.`, `1st Qu.`, `Median`, `3rd Qu.`, `Max,`) and `Mean` values shown by `summary`, we can see that `nm`, `nmqm`, `wfl`, and `rooms` are properly formated and within reasonable ranges. By definition of the variables, we should have that

\begin{eqnarray}
\frac{\texttt{nm}}{\texttt{wfl}} &=&  \texttt{nmqm}
\end{eqnarray}

Let's check whether this relationship holds by comparing the summary of `nmqm` and $\frac{\texttt{nm}}{\texttt{wfl}}$ and having a look at the sum of absolute errors (in relative terms):

```{r}
summary(miete$nmqm)
nmqm2 <- miete$nm / miete$wfl
summary(nmqm2)
sum(abs(miete$nmqm - nmqm2)) / sum(nmqm2)
```

There are only minor differences which are negligible and probably caused by rounding originally numeric values of `wfl` to integers.
Since the year of construction, `bj`, contains values of years, we can convert it to integers:

```{r Convert$bj}
miete$bj <- as.integer(miete$bj)
```

The factor variable `bez`, indicating the district where the respective flat is located, has 25 levels. Let's have a closer look:

```{r Table$bez}
table(miete$bez)
```

The remaining variables (`wohngut`, `wohnbest`, `ww0`, `zh0`, `badkach0`, `badextra`, `kueche`) are all binary and valid which we can see from the summary above, since `Min.`\ is 0 and `Max.`\ is 1 for all those variables. Let's convert them properly:

```{r ConvertBinaries}
miete[7:13] <- lapply(miete[7:13], as.logical)
```

Now, we have a nice and tidy dataset and can proceed exploring our data.


<!-- If we also want to get some extra information like the standard deviation and maybe skew and kurtosis, we can use the `psych` library and the containing function `describe`. In this case we include all variables. -->

```{r}
# library(psych)
# describe(miete)
```

### Exploratory Analysis

Before building a model, we would like to better understand our data by using different plots and methods of analysis.

The dependent variable of our model will be `nm`. Therefore, it would be nice to have a look at some scatterplots with different regressors to get a first impression on the correlation between the dependent variable and the potential regressors.

Net rent per $m^2$ (`nmqm`) is the net rent (`nm`) per living space (`wfl`) as we have already seen above. Therefore, it is not appropriate to use `nmqm` as an explanatory variable because we would use rent pricing information to explain rent pricing information. Since we have living space `wfl` as a sepearte variable, `nmqm` is of no additional explanatory value. Hence, we would expect `nm` to be highly positively correlated with `nmqm`. Let's verify our reasoning with a scatterplot:

```{r Exp$nmqm}
plot(miete$nmqm,
     miete$nm,
     xlab = expression(paste("Net rent per m"^"2", " in EUR")),
     ylab = "Net Rent in EUR")
```

As expected, we can see a strong positive correlation.

Next, we will have a look at living space `wfl`. Naturally, one would assume prices to be higher for larger spaces. Let's have a look:

```{r Exp$wfl}
plot(miete$wfl,
     miete$nm,
     xlab = expression(paste("Living Space in m"^"2")),
     ylab = "Net Rent in EUR")
```

Indeed, there seems to be a positive correlation and therefore we expect living space to be a significant regressor later in our model.

A further potential regressor are the number of rooms (`rooms`) available in a flat. Number of rooms ranges from 1 to 6 rooms at most. Therefore, a boxplot would be nice to get a first impression on how net rent varies with room number:

```{r Exp$rooms}
boxplot(nm ~ as.factor(rooms), data = miete,
        xlab = "Number of Rooms",
        ylab = "Net Rent in EUR")
```

From the boxplot, we can observe higher net rents for flats with more rooms (although from 5 to 6 rooms there doesn't seem to be a significant difference). But we have to be careful with our reasoning. Since more rooms most likely mean larger living space (or the other way round), this positive relationship in the plot could already be explained by `wfl`. For example, if people generally prefer more open rooms for some fixed living space, i.e.\ fewer rooms per space, and are willing to pay more for this kind of architechture, then there could even be a reducing effect of more rooms on renting prices, when pure living space has already explained a higher renting price level.

For the effect of the year of construction on net rents, we do not have a clear intuition, since very old, but renovated buildings could also be of high value. Let's look at the scatterplot:

```{r Exp$bj}
plot(miete$bj,
     miete$nm,
     xlab = "Year of Construction",
     ylab = "Net Rent in EUR")
```

From the plot, there doesn't seem to be a significant relationship.

Another candidate for providing explanatory value on rent levels is the district, where the respective property is located (`bez`). For example, one would expect higher levels in districts close to the center of Munich. Overall, the observations in our dataset are located in 25 different districts. A complete list of all districts of Munich for example can be found at [en.wikipedia.org/wiki/Boroughs_of_Munich](https://en.wikipedia.org/wiki/Boroughs_of_Munich). Munich has 25 districts in total, i.e.\ the dataset contains flats from all districts. Let's consider a boxplot:

```{r Exp$bez}
boxplot(nm ~ bez, data = miete,
        xlab = "District of flat",
        ylab = "Net Rent in EUR")
```

From the boxplot we can see, that rental prices in district 1 are relatively
high. This is the “Altstadt-Lehel”-district, which is the center of Munich.
Since we will incorporate the factor variable `bez` as a dummy-variables in our
linear regression, the “Altstadt-Lehel”-district will be our reference-district
(zero encoded). Hence, we expect from looking at the boxplot, that different
districts will have a decreasing effect on rental prices when compared to the
benchmark “Altstadt-Lehel”. For example, lower rental prices could be expected in district 11 (“Milbertshofen-Am Hart”) or district 14 (“Berg am Laim”).

To complete our exploratory analysis, let's consider a further plot, showing boxplots of all binary variables:

```{r Exp$Binary}
# Prepare for multiple base plots
par(mfrow = c(2,4))

# Labels
nmLab <- "Net Rent in EUR"
BinLab <- c("Good Residential Area? (Y=1, N=0)",
            "Best Residential Area? (Y=1, N=0)",
            "Hot Water Supply? (Y=0, N=1)",
            "Central Heating? (Y=0, N=1)",
            "Tiled Bathroom? (Y=0, N=1)",
            "Optional Extras in Bathroom? (Y=1, N=0)",
            "Luxury Kitchen? (Y=1, N=0)")

# Plot
for (i in 7:13){
    boxplot(formula(paste("nm ~ ", names(miete)[i])),
            data = miete,
            xlab = BinLab[i-6],
            ylab = nmLab)
}

# Reset to single base plot
par(mfrow = c(1,1))

# Maybe convert binary variables to factor variables with proper Yes/No
# labels... Also clean up xlabs...
```

```{r Covariance}
# Maybe plot covariance matrix of regressors to see relationships between regressors?
```


### Identification of relevant regressors and model fit
<!-- Original draft -->

To idenfity relevant regressors we can apply `lm()`, which calculates a linear model, to all variables. The first argument of the function is the formular. In our case we want to do a regression of the rent in EUR (`miete\$nm`) on all other variables (we can use the `.` to include all variables). In the second argument we set our dataset.

```{r}
regrel <- lm(miete$nm ~ ., data = miete)
```

We can omit all variables which have no significant slope. To get the slope we can have a look to the `summary` of the result of the linear regression.

```{r}
summary(regrel)
```

We would suggest to include all variables which are significant on a $99\%$ level (* or **). With the relevant variables we can fit the regression.

```{r}
summary(lm(miete$nm ~ miete$nmqm + miete$wfl + miete$wohnbest +
             miete$ww0 + miete$kueche, data = miete))
```

### Discussion of Model Fit and Interpretation of the Model

<!-- Check Fahrmeier on analysis -->

## References
<!-- Add some nice references to the dataset maybe -->